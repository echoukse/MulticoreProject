% !TEX root = report.tex
\section{Background}
Let us first discuss the concepts of Queue delegation and elimination in detail.
\subsection{Queue Delegation}
Using locks on shared data structure is a very common practice. On doing so, each operation on the shared data structure by a thread, needs it to first acquire the associated lock. Even though fine grained locks perform better than coarse grained locks, there is still a lot of performance hit. Queue delegation is a method to reduce the hit by allowing threads to outsource their shared data structure operations to a delegate thread. This is done by pushing the task into a delegation queue. Once the task is in queue, the thread can carry on with its execution and does not need to wait on the result.
The delegate thread reads tasks from the delegation queue, and executes them one by one, giving out the results to the associated threads. Note that since a single thread is executing the operations on the shared data structure, no locks are required.
There are several ways to implement the Queue delegation. One of the main decisions to make is that whether we want a single thread to remain the delegate thread throughout the execution, or can any thread become a delegate thread. In the QD Lock libraries we have used, the second approach is implemented. The threads, upon reaching a shared data structure operation, try to acquire a lock, to become the delegate thread. If they fail to acquire the lock, they put the task into the delegation queue and leave. Instead, if they do acquire the lock, they execute their task, and all the tasks in the delegation queue, till the queue becomes empty eventually. Once this happens, the delegate thread gives up the lock and leaves. Upon contention, a thread may need to become the delegate thread for very long periods, affecting execution of that thread. To fix this, we have a limit on the number of tasks in the delegation queue, which we call delegation queue length. Once this limit is reached, the delegation queue stops accepting tasks. The choice of the delegation queue length is therefore an important factor in the performance.

\subsection{Elimination}
Elimination identifies the operations on a shared data structure, which have reverse semantics. Such operations can be made to collide outside the shared data structure, and return, without ever getting to access the actual structure. This helps  reduce contention. 
The elimination uses an elimination array, which has multiple slots. Each slot can be in a waiting, busy or empty state. An operation, on finding an empty slot, changes it to waiting and waits. Another operation comes in, and on finding the slot waiting, makes it busy. In case these two operations are of reverse semantics, our work is done. We then return both the operations with the expected results. The choice of number of slots in the elimination array is an important one, since too big an array will lead to lesser collisions.


